{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inception_Train-Test_2class.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPORWvEajkpyL0gY3u6l6bQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PondKann/CXR-Project/blob/main/Inception_Train_Test_2class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Pretrained // Sampling Abnormal   ยังไม่รัน\n",
        "\n",
        "2) 0-100 // Sampling Abnormal  ยังไม่รัน"
      ],
      "metadata": {
        "id": "hNGDvj0JKMrU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpnf_sft9x4-"
      },
      "source": [
        "#### import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Psng6eJUdzUG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torchsummary import summary\n",
        "from skimage.io import imread, imsave\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f-PDKiLl2iC"
      },
      "outputs": [],
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model\n",
        "from imutils import paths\n",
        "import argparse\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import metrics\n",
        "from scipy.stats import zscore\n",
        "\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import savefig\n",
        "\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1e52UqdwPp8"
      },
      "source": [
        "#### Load data // KKU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlcukkP7fnhB",
        "outputId": "0fa4b2df-f0b0-4047-fc2c-72a888fff3ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0w8suy5ofqx_"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/My Drive/Senior Project/CXR Image3class/Image'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhqPQxA42jeC"
      },
      "source": [
        "train 3 class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Jrg5mt_RvJT"
      },
      "outputs": [],
      "source": [
        "Normal151_dir = os.path.join(data_dir,'Normal151')\n",
        "TB150_dir = os.path.join(data_dir,'TB150')\n",
        "CA150_dir = os.path.join(data_dir,'CA150')\n",
        "\n",
        "All_3class_dir = os.path.join(data_dir,'All_3class')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TdmiFUwh-BT_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_dJIpAJ3n_I"
      },
      "source": [
        "#### Load data // Gmail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2d2705a-eadd-4da5-ee8f-707634cb2f8a",
        "id": "X9hd2pU13n_J"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCHunkNk3n_J"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/My Drive/Senior Project/CXR Image3class'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwTPsWNE3n_J"
      },
      "source": [
        "train 3 class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrXH05fh3n_K"
      },
      "outputs": [],
      "source": [
        "Normal151_dir = os.path.join(data_dir,'Normal151')\n",
        "TB150_dir = os.path.join(data_dir,'TB150')\n",
        "CA150_dir = os.path.join(data_dir,'CA150')\n",
        "\n",
        "All_3class_dir = os.path.join(data_dir,'All_3class')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "i5V5DnHg3n_K"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g71UX3BnhMU5"
      },
      "source": [
        "#### Data 2 class  + Sampling data\n",
        "ข้อมูลใน All_3class_dir รวมภาพทั้ง 3 คลาส รวม 451 ภาพ TB150, Normal151 และ CA150 (CA คือ lungcancer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbgiHWi9hMU6"
      },
      "outputs": [],
      "source": [
        "Normal151_dir = os.path.join(data_dir,'Normal151')\n",
        "TB150_dir = os.path.join(data_dir,'TB150')\n",
        "CA150_dir = os.path.join(data_dir,'CA150')\n",
        "\n",
        "All_3class_dir = os.path.join(data_dir,'All_3class')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhIRkVUDhMU7"
      },
      "outputs": [],
      "source": [
        "normal = []\n",
        "for i in range(len(os.listdir(Normal151_dir))):\n",
        "    img = os.listdir(Normal151_dir)[i]\n",
        "    normal.append(img)\n",
        "    \n",
        "tnormal = pd.DataFrame({'ImageName':[normal][0],\n",
        "                                       'NameType': \"Normal\"  })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lcw67LQyhMU7"
      },
      "outputs": [],
      "source": [
        "tuberculosis = []\n",
        "for i in range(len(os.listdir(TB150_dir))):\n",
        "    img = os.listdir(TB150_dir)[i]\n",
        "    tuberculosis.append(img)\n",
        "\n",
        "ttuberculosis = pd.DataFrame({'ImageName':[tuberculosis][0],\n",
        "                                       'NameType': \"Abnormal\"  })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFBTCuPEhMU8"
      },
      "outputs": [],
      "source": [
        "lungcancer = []\n",
        "for i in range(len(os.listdir(CA150_dir))):\n",
        "    img = os.listdir(CA150_dir)[i]\n",
        "    lungcancer.append(img)\n",
        "\n",
        "tlungcancer = pd.DataFrame({'ImageName':[lungcancer][0],\n",
        "                                       'NameType': \"Abnormal\"  })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "FdG7BpQihMU8",
        "outputId": "dd37da61-21bc-4451-98dd-a5b0dce7212a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b76a75e5-216a-41f3-a1aa-e7adb754240e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageName</th>\n",
              "      <th>NameType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>ca2.jpg</td>\n",
              "      <td>Abnormal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>ca26.jpg</td>\n",
              "      <td>Abnormal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>ca8.jpg</td>\n",
              "      <td>Abnormal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b76a75e5-216a-41f3-a1aa-e7adb754240e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b76a75e5-216a-41f3-a1aa-e7adb754240e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b76a75e5-216a-41f3-a1aa-e7adb754240e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    ImageName  NameType\n",
              "147   ca2.jpg  Abnormal\n",
              "148  ca26.jpg  Abnormal\n",
              "149   ca8.jpg  Abnormal"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "data_train3 = pd.concat([tnormal[:-1], ttuberculosis, tlungcancer])\n",
        "data_train3[-3:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train3.shape"
      ],
      "metadata": {
        "id": "eT6-CPGZl503",
        "outputId": "16ce3973-46f7-435a-9fd9-2388553064a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(450, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sampling data"
      ],
      "metadata": {
        "id": "AOUO1sdiNfD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tabnormal= pd.concat([ttuberculosis, tlungcancer])\n",
        "tabnormal = tabnormal.sample(n=150, random_state=40)\n",
        "data_train3 = pd.concat([tnormal[:-1], tabnormal])"
      ],
      "metadata": {
        "id": "r6R5PQsZOboU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train3.to_excel(\"data_2class_sampling.xlsx\")"
      ],
      "metadata": {
        "id": "SXmWc4qb5jR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pretrained Sampling Abnormal"
      ],
      "metadata": {
        "id": "m8QzyY3siWUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1 sig pre bi sgd\n"
      ],
      "metadata": {
        "id": "0mTaT-mmGxgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 1\n",
        "filepath = \"model1_sig_pre_bi_sgd\"                  ##\n",
        "filename = f\" {filepath}.h5 \"\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=2)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                          \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "acb4e593-91fd-41c4-caea-7fe6c4fce437",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf9vmDoUGxgB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:03<00:00, 95.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train_Incep, x_test_Incep, y_train_Incep, y_test_Incep ) = train_test_split(data_Incep, labels_Incep,\n",
        "\t                                                                                                test_size=0.25, random_state=40)"
      ],
      "metadata": {
        "id": "HKfOzUqCeuH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "base_model_Incep.trainable = False\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=2, activation=\"sigmoid\")(average_pooling_layer)   # unit 2\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "                                                ###\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "\n",
        "print(classification_report(y_test_Incep.argmax(axis=1),   pred_Incep.argmax(axis=1), target_names=le_Incep.classes_))\n",
        "\n",
        "\n",
        "#download ไฟล์ลงเครื่อง\n",
        "from google.colab import files\n",
        "files.download(filepath)     "
      ],
      "metadata": {
        "id": "fk7BYIpCeuiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly import __version__\n",
        "%matplotlib inline\n",
        "\n",
        "import plotly.offline as pyo\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import iplot\n",
        "\n",
        "import cufflinks as cf\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
        "\n",
        "\n",
        "cf.go_offline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "404c1287-2b0e-4ff9-f82f-25f04d90eedd",
        "id": "FF5qDkapT-ss"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "H_Dense = H_Incep                            ##\n",
        "pred_Dense = pred_Incep                 ##\n",
        "\n",
        "accuracy = H_Dense.history['accuracy']\n",
        "val_accuracy  = H_Dense.history['val_accuracy']\n",
        "\n",
        "loss = H_Dense.history['loss']\n",
        "val_loss = H_Dense.history['val_loss']\n",
        "plt.figure(figsize=(20,15))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(accuracy, label = \"Training accuracy\")\n",
        "plt.plot(val_accuracy, label=\"Validation accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation accuracy\")\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(loss, label = \"Training loss\")\n",
        "plt.plot(val_loss, label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation loss\")\n",
        "\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bEM4hmh7T-st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_Incep.argmax(axis=1)            ##\n",
        "y_true  = y_test_Incep.argmax(axis=1)\n",
        "y_test = y_test_Incep.argmax(axis=1)\n",
        "\n",
        "class_names = le_Incep.classes_\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.OrRd):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lcmGExVlT-st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rD4C5Eo9grU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(filepath)"
      ],
      "metadata": {
        "id": "sz8zMOfbcUK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_model = model.predict(x_test_Incep)\n",
        "\n",
        "print(classification_report(y_test_Incep.argmax(axis=1),   pred_model.argmax(axis=1), target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "T-nz6HmecUK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_model.argmax(axis=1)            ##\n",
        "y_true  = y_test_Incep.argmax(axis=1)\n",
        "y_test = y_test_Incep.argmax(axis=1)\n",
        "\n",
        "class_names = le_Incep.classes_\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.OrRd):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NrPEVqxBgrOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  8 sig pre bi \n"
      ],
      "metadata": {
        "id": "yOXR3LnbhTug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 8\n",
        "filepath = \"model8_sig_pre_bi\"                  ##\n",
        "filename = f\" {filepath}.h5 \"\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=2)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                          \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "acb4e593-91fd-41c4-caea-7fe6c4fce437",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcdSW3mlhTuh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:03<00:00, 95.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train_Incep, x_test_Incep, y_train_Incep, y_test_Incep ) = train_test_split(data_Incep, labels_Incep,\n",
        "\t                                                                                                test_size=0.25, random_state=40)"
      ],
      "metadata": {
        "id": "mvkhfK0JhTuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "base_model_Incep.trainable = False\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=2, activation=\"sigmoid\")(average_pooling_layer)   # unit 2\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "                                                ###\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "\n",
        "print(classification_report(y_test_Incep.argmax(axis=1),   pred_Incep.argmax(axis=1), target_names=le_Incep.classes_))\n",
        "\n",
        "\n",
        "#download ไฟล์ลงเครื่อง\n",
        "from google.colab import files\n",
        "files.download(filepath)     "
      ],
      "metadata": {
        "id": "BImeh0eXhTuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly import __version__\n",
        "%matplotlib inline\n",
        "\n",
        "import plotly.offline as pyo\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import iplot\n",
        "\n",
        "import cufflinks as cf\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
        "\n",
        "\n",
        "cf.go_offline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "404c1287-2b0e-4ff9-f82f-25f04d90eedd",
        "id": "V2L3hTLShTuj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "H_Dense = H_Incep                            ##\n",
        "pred_Dense = pred_Incep                 ##\n",
        "\n",
        "accuracy = H_Dense.history['accuracy']\n",
        "val_accuracy  = H_Dense.history['val_accuracy']\n",
        "\n",
        "loss = H_Dense.history['loss']\n",
        "val_loss = H_Dense.history['val_loss']\n",
        "plt.figure(figsize=(20,15))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(accuracy, label = \"Training accuracy\")\n",
        "plt.plot(val_accuracy, label=\"Validation accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation accuracy\")\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(loss, label = \"Training loss\")\n",
        "plt.plot(val_loss, label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation loss\")\n",
        "\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C4jGqwMAhTuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_Incep.argmax(axis=1)            ##\n",
        "y_true  = y_test_Incep.argmax(axis=1)\n",
        "y_test = y_test_Incep.argmax(axis=1)\n",
        "\n",
        "class_names = le_Incep.classes_\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.OrRd):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W_OpqW3shTuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tHnsgxx9hTuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(filepath)"
      ],
      "metadata": {
        "id": "GDp4F80xhTul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_model = model.predict(x_test_Incep)\n",
        "\n",
        "print(classification_report(y_test_Incep.argmax(axis=1),   pred_model.argmax(axis=1), target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "pvEAr1VShTum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_model.argmax(axis=1)            ##\n",
        "y_true  = y_test_Incep.argmax(axis=1)\n",
        "y_test = y_test_Incep.argmax(axis=1)\n",
        "\n",
        "class_names = le_Incep.classes_\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.OrRd):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7kaAsyQWhTun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 16 sig pre bi adam\n"
      ],
      "metadata": {
        "id": "qm4cZxOXhpLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16\n",
        "filepath = \"model16_sig_pre_bi_adam\"                  ##\n",
        "filename = f\" {filepath}.h5 \"\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=2)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                          \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "acb4e593-91fd-41c4-caea-7fe6c4fce437",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCopN78ehpLS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:03<00:00, 95.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train_Incep, x_test_Incep, y_train_Incep, y_test_Incep ) = train_test_split(data_Incep, labels_Incep,\n",
        "\t                                                                                                test_size=0.25, random_state=40)"
      ],
      "metadata": {
        "id": "usC8qo0jhpLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "base_model_Incep.trainable = False\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=2, activation=\"sigmoid\")(average_pooling_layer)   # unit 2\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "                                                ###\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "\n",
        "print(classification_report(y_test_Incep.argmax(axis=1),   pred_Incep.argmax(axis=1), target_names=le_Incep.classes_))\n",
        "\n",
        "\n",
        "#download ไฟล์ลงเครื่อง\n",
        "from google.colab import files\n",
        "files.download(filepath)     "
      ],
      "metadata": {
        "id": "nIL5oYLwhpLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly import __version__\n",
        "%matplotlib inline\n",
        "\n",
        "import plotly.offline as pyo\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import iplot\n",
        "\n",
        "import cufflinks as cf\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
        "\n",
        "\n",
        "cf.go_offline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "404c1287-2b0e-4ff9-f82f-25f04d90eedd",
        "id": "HJWGp3FnhpLU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "H_Dense = H_Incep                            ##\n",
        "pred_Dense = pred_Incep                 ##\n",
        "\n",
        "accuracy = H_Dense.history['accuracy']\n",
        "val_accuracy  = H_Dense.history['val_accuracy']\n",
        "\n",
        "loss = H_Dense.history['loss']\n",
        "val_loss = H_Dense.history['val_loss']\n",
        "plt.figure(figsize=(20,15))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(accuracy, label = \"Training accuracy\")\n",
        "plt.plot(val_accuracy, label=\"Validation accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation accuracy\")\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(loss, label = \"Training loss\")\n",
        "plt.plot(val_loss, label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation loss\")\n",
        "\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rSRoc6yChpLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_Incep.argmax(axis=1)            ##\n",
        "y_true  = y_test_Incep.argmax(axis=1)\n",
        "y_test = y_test_Incep.argmax(axis=1)\n",
        "\n",
        "class_names = le_Incep.classes_\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.OrRd):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QgPHr2WuhpLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f37sBtkchpLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(filepath)"
      ],
      "metadata": {
        "id": "SFK_rff8hpLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_model = model.predict(x_test_Incep)\n",
        "\n",
        "print(classification_report(y_test_Incep.argmax(axis=1),   pred_model.argmax(axis=1), target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "PLasgkhfhpLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_model.argmax(axis=1)            ##\n",
        "y_true  = y_test_Incep.argmax(axis=1)\n",
        "y_test = y_test_Incep.argmax(axis=1)\n",
        "\n",
        "class_names = le_Incep.classes_\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.OrRd):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y2CE_qUPhpLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 16 sig pre bi sgd\n"
      ],
      "metadata": {
        "id": "0HwnWh8NhwBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16\n",
        "filepath = \"model16_sig_pre_bi_sgd\"                  ##\n",
        "filename = f\" {filepath}.h5 \"\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=2)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                          \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "acb4e593-91fd-41c4-caea-7fe6c4fce437",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA8zy6WDhwBV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:03<00:00, 95.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train_Incep, x_test_Incep, y_train_Incep, y_test_Incep ) = train_test_split(data_Incep, labels_Incep,\n",
        "\t                                                                                                test_size=0.25, random_state=40)"
      ],
      "metadata": {
        "id": "2rxvmHRRhwBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "base_model_Incep.trainable = False\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=2, activation=\"sigmoid\")(average_pooling_layer)   # unit 2\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "                                                ###\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "\n",
        "print(classification_report(y_test_Incep.argmax(axis=1),   pred_Incep.argmax(axis=1), target_names=le_Incep.classes_))\n",
        "\n",
        "\n",
        "#download ไฟล์ลงเครื่อง\n",
        "from google.colab import files\n",
        "files.download(filepath)     "
      ],
      "metadata": {
        "id": "Z0HZHj4WhwBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly import __version__\n",
        "%matplotlib inline\n",
        "\n",
        "import plotly.offline as pyo\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import iplot\n",
        "\n",
        "import cufflinks as cf\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
        "\n",
        "\n",
        "cf.go_offline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "404c1287-2b0e-4ff9-f82f-25f04d90eedd",
        "id": "aKGdQ65zhwBX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "H_Dense = H_Incep                            ##\n",
        "pred_Dense = pred_Incep                 ##\n",
        "\n",
        "accuracy = H_Dense.history['accuracy']\n",
        "val_accuracy  = H_Dense.history['val_accuracy']\n",
        "\n",
        "loss = H_Dense.history['loss']\n",
        "val_loss = H_Dense.history['val_loss']\n",
        "plt.figure(figsize=(20,15))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(accuracy, label = \"Training accuracy\")\n",
        "plt.plot(val_accuracy, label=\"Validation accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation accuracy\")\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(loss, label = \"Training loss\")\n",
        "plt.plot(val_loss, label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation loss\")\n",
        "\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-3AFfAqXhwBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_Incep.argmax(axis=1)            ##\n",
        "y_true  = y_test_Incep.argmax(axis=1)\n",
        "y_test = y_test_Incep.argmax(axis=1)\n",
        "\n",
        "class_names = le_Incep.classes_\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.OrRd):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AcePfQf1hwBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "F5y6Kp2ahwBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(filepath)"
      ],
      "metadata": {
        "id": "NunGg43_hwBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_model = model.predict(x_test_Incep)\n",
        "\n",
        "print(classification_report(y_test_Incep.argmax(axis=1),   pred_model.argmax(axis=1), target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "fvlENcbOhwBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_model.argmax(axis=1)            ##\n",
        "y_true  = y_test_Incep.argmax(axis=1)\n",
        "y_test = y_test_Incep.argmax(axis=1)\n",
        "\n",
        "class_names = le_Incep.classes_\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.OrRd):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TkpV27CuhwBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 32 sig pre bi \n"
      ],
      "metadata": {
        "id": "Xk2t-VtbiEtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 32\n",
        "filepath = \"model32_sig_pre_bi\"                  ##\n",
        "filename = f\" {filepath}.h5 \"\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=2)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                          \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "acb4e593-91fd-41c4-caea-7fe6c4fce437",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEw1n4KjiEtc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:03<00:00, 95.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train_Incep, x_test_Incep, y_train_Incep, y_test_Incep ) = train_test_split(data_Incep, labels_Incep,\n",
        "\t                                                                                                test_size=0.25, random_state=40)"
      ],
      "metadata": {
        "id": "Kfub9rTdiEtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "base_model_Incep.trainable = False\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=2, activation=\"sigmoid\")(average_pooling_layer)   # unit 2\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "                                                ###\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "\n",
        "print(classification_report(y_test_Incep.argmax(axis=1),   pred_Incep.argmax(axis=1), target_names=le_Incep.classes_))\n",
        "\n",
        "\n",
        "#download ไฟล์ลงเครื่อง\n",
        "from google.colab import files\n",
        "files.download(filepath)     "
      ],
      "metadata": {
        "id": "Dl9BHk7iiEtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly import __version__\n",
        "%matplotlib inline\n",
        "\n",
        "import plotly.offline as pyo\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import iplot\n",
        "\n",
        "import cufflinks as cf\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
        "\n",
        "\n",
        "cf.go_offline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "404c1287-2b0e-4ff9-f82f-25f04d90eedd",
        "id": "NlpPMUoHiEtf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "H_Dense = H_Incep                            ##\n",
        "pred_Dense = pred_Incep                 ##\n",
        "\n",
        "accuracy = H_Dense.history['accuracy']\n",
        "val_accuracy  = H_Dense.history['val_accuracy']\n",
        "\n",
        "loss = H_Dense.history['loss']\n",
        "val_loss = H_Dense.history['val_loss']\n",
        "plt.figure(figsize=(20,15))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(accuracy, label = \"Training accuracy\")\n",
        "plt.plot(val_accuracy, label=\"Validation accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation accuracy\")\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(loss, label = \"Training loss\")\n",
        "plt.plot(val_loss, label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation loss\")\n",
        "\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DVYV65I8iEtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_Incep.argmax(axis=1)            ##\n",
        "y_true  = y_test_Incep.argmax(axis=1)\n",
        "y_test = y_test_Incep.argmax(axis=1)\n",
        "\n",
        "class_names = le_Incep.classes_\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.OrRd):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VHYijklciEtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4KfF4bWziEtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(filepath)"
      ],
      "metadata": {
        "id": "XZOjhhlYiEtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_model = model.predict(x_test_Incep)\n",
        "\n",
        "print(classification_report(y_test_Incep.argmax(axis=1),   pred_model.argmax(axis=1), target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "_BPlWg3DiEtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_model.argmax(axis=1)            ##\n",
        "y_true  = y_test_Incep.argmax(axis=1)\n",
        "y_test = y_test_Incep.argmax(axis=1)\n",
        "\n",
        "class_names = le_Incep.classes_\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.OrRd):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T9fEayQPiEtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0-100 Sampling Abnormal"
      ],
      "metadata": {
        "id": "VNgHa4HBicXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1 sig fine bi sgd\n"
      ],
      "metadata": {
        "id": "uLcjbgfkicXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 1\n",
        "filepath = \"model1_sig_fine_bi_sgd\"                  ##\n",
        "filename = f\" {filepath}.h5 \"\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=2)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                          \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "acb4e593-91fd-41c4-caea-7fe6c4fce437",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64PP8CjVicXd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:03<00:00, 95.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train_Incep, x_test_Incep, y_train_Incep, y_test_Incep ) = train_test_split(data_Incep, labels_Incep,\n",
        "\t                                                                                                test_size=0.25, random_state=40)"
      ],
      "metadata": {
        "id": "Bn-kArHmicXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=2, activation=\"sigmoid\")(average_pooling_layer)   # unit 2\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "                                                ###\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "\n",
        "print(classification_report(y_test_Incep.argmax(axis=1),   pred_Incep.argmax(axis=1), target_names=le_Incep.classes_))\n",
        "\n",
        "\n",
        "#download ไฟล์ลงเครื่อง\n",
        "from google.colab import files\n",
        "files.download(filepath)     "
      ],
      "metadata": {
        "id": "flBVQYvgicXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly import __version__\n",
        "%matplotlib inline\n",
        "\n",
        "import plotly.offline as pyo\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import iplot\n",
        "\n",
        "import cufflinks as cf\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
        "\n",
        "\n",
        "cf.go_offline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "404c1287-2b0e-4ff9-f82f-25f04d90eedd",
        "id": "oypH8qeAicXf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "H_Dense = H_Incep                            ##\n",
        "pred_Dense = pred_Incep                 ##\n",
        "\n",
        "accuracy = H_Dense.history['accuracy']\n",
        "val_accuracy  = H_Dense.history['val_accuracy']\n",
        "\n",
        "loss = H_Dense.history['loss']\n",
        "val_loss = H_Dense.history['val_loss']\n",
        "plt.figure(figsize=(20,15))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(accuracy, label = \"Training accuracy\")\n",
        "plt.plot(val_accuracy, label=\"Validation accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation accuracy\")\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(loss, label = \"Training loss\")\n",
        "plt.plot(val_loss, label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation loss\")\n",
        "\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "opWvbY3TicXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_Incep.argmax(axis=1)            ##\n",
        "y_true  = y_test_Incep.argmax(axis=1)\n",
        "y_test = y_test_Incep.argmax(axis=1)\n",
        "\n",
        "class_names = le_Incep.classes_\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.OrRd):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d_nAb2BvicXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xN9MGMPUicXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(filepath)"
      ],
      "metadata": {
        "id": "svFRBkFficXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_model = model.predict(x_test_Incep)\n",
        "\n",
        "print(classification_report(y_test_Incep.argmax(axis=1),   pred_model.argmax(axis=1), target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "BVHhjb4qicXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_model.argmax(axis=1)            ##\n",
        "y_true  = y_test_Incep.argmax(axis=1)\n",
        "y_test = y_test_Incep.argmax(axis=1)\n",
        "\n",
        "class_names = le_Incep.classes_\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.OrRd):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4JTROaGYicXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8 sig fine bi sgd\n"
      ],
      "metadata": {
        "id": "DWZNIb1Ei7Qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 8\n",
        "filepath = \"model8_sig_fine_bi_sgd\"                  ##\n",
        "filename = f\" {filepath}.h5 \"\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=2)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                          \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "acb4e593-91fd-41c4-caea-7fe6c4fce437",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuSlsmCNi7Q2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:03<00:00, 95.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train_Incep, x_test_Incep, y_train_Incep, y_test_Incep ) = train_test_split(data_Incep, labels_Incep,\n",
        "\t                                                                                                test_size=0.25, random_state=40)"
      ],
      "metadata": {
        "id": "8P6W7_Koi7Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=2, activation=\"sigmoid\")(average_pooling_layer)   # unit 2\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "                                                ###\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "\n",
        "print(classification_report(y_test_Incep.argmax(axis=1),   pred_Incep.argmax(axis=1), target_names=le_Incep.classes_))\n",
        "\n",
        "\n",
        "#download ไฟล์ลงเครื่อง\n",
        "from google.colab import files\n",
        "files.download(filepath)     "
      ],
      "metadata": {
        "id": "cYSbWW9pi7Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly import __version__\n",
        "%matplotlib inline\n",
        "\n",
        "import plotly.offline as pyo\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import iplot\n",
        "\n",
        "import cufflinks as cf\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
        "\n",
        "\n",
        "cf.go_offline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "404c1287-2b0e-4ff9-f82f-25f04d90eedd",
        "id": "KClLzQ6Ki7Q3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "H_Dense = H_Incep                            ##\n",
        "pred_Dense = pred_Incep                 ##\n",
        "\n",
        "accuracy = H_Dense.history['accuracy']\n",
        "val_accuracy  = H_Dense.history['val_accuracy']\n",
        "\n",
        "loss = H_Dense.history['loss']\n",
        "val_loss = H_Dense.history['val_loss']\n",
        "plt.figure(figsize=(20,15))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(accuracy, label = \"Training accuracy\")\n",
        "plt.plot(val_accuracy, label=\"Validation accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation accuracy\")\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(loss, label = \"Training loss\")\n",
        "plt.plot(val_loss, label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation loss\")\n",
        "\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JF66lMg2i7Q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_Incep.argmax(axis=1)            ##\n",
        "y_true  = y_test_Incep.argmax(axis=1)\n",
        "y_test = y_test_Incep.argmax(axis=1)\n",
        "\n",
        "class_names = le_Incep.classes_\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.OrRd):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3OGH1fyUi7Q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Erm-dBfYi7Q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(filepath)"
      ],
      "metadata": {
        "id": "x5PAMQZZi7Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_model = model.predict(x_test_Incep)\n",
        "\n",
        "print(classification_report(y_test_Incep.argmax(axis=1),   pred_model.argmax(axis=1), target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "A9UNKotUi7Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_model.argmax(axis=1)            ##\n",
        "y_true  = y_test_Incep.argmax(axis=1)\n",
        "y_test = y_test_Incep.argmax(axis=1)\n",
        "\n",
        "class_names = le_Incep.classes_\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.OrRd):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mEMm9vaIi7Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 16 sig fine bi \n"
      ],
      "metadata": {
        "id": "kL7S5ZAnjHdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16\n",
        "filepath = \"model16_sig_fine_bi\"                  ##\n",
        "filename = f\" {filepath}.h5 \"\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=2)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                          \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "acb4e593-91fd-41c4-caea-7fe6c4fce437",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXFisq-0jHdB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:03<00:00, 95.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train_Incep, x_test_Incep, y_train_Incep, y_test_Incep ) = train_test_split(data_Incep, labels_Incep,\n",
        "\t                                                                                                test_size=0.25, random_state=40)"
      ],
      "metadata": {
        "id": "khPAKFAvjHdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=2, activation=\"sigmoid\")(average_pooling_layer)   # unit 2\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "                                                ###\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "\n",
        "print(classification_report(y_test_Incep.argmax(axis=1),   pred_Incep.argmax(axis=1), target_names=le_Incep.classes_))\n",
        "\n",
        "\n",
        "#download ไฟล์ลงเครื่อง\n",
        "from google.colab import files\n",
        "files.download(filepath)     "
      ],
      "metadata": {
        "id": "Potw8jR7jHdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly import __version__\n",
        "%matplotlib inline\n",
        "\n",
        "import plotly.offline as pyo\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import iplot\n",
        "\n",
        "import cufflinks as cf\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
        "\n",
        "\n",
        "cf.go_offline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "404c1287-2b0e-4ff9-f82f-25f04d90eedd",
        "id": "BPQsoKbhjHdD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "H_Dense = H_Incep                            ##\n",
        "pred_Dense = pred_Incep                 ##\n",
        "\n",
        "accuracy = H_Dense.history['accuracy']\n",
        "val_accuracy  = H_Dense.history['val_accuracy']\n",
        "\n",
        "loss = H_Dense.history['loss']\n",
        "val_loss = H_Dense.history['val_loss']\n",
        "plt.figure(figsize=(20,15))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(accuracy, label = \"Training accuracy\")\n",
        "plt.plot(val_accuracy, label=\"Validation accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation accuracy\")\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(loss, label = \"Training loss\")\n",
        "plt.plot(val_loss, label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation loss\")\n",
        "\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lyxpmItpjHdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_Incep.argmax(axis=1)            ##\n",
        "y_true  = y_test_Incep.argmax(axis=1)\n",
        "y_test = y_test_Incep.argmax(axis=1)\n",
        "\n",
        "class_names = le_Incep.classes_\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.OrRd):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SLbhS6tEjHdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jUVYULRojHdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(filepath)"
      ],
      "metadata": {
        "id": "aHqPED6yjHdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_model = model.predict(x_test_Incep)\n",
        "\n",
        "print(classification_report(y_test_Incep.argmax(axis=1),   pred_model.argmax(axis=1), target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "epcPTlq9jHdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_model.argmax(axis=1)            ##\n",
        "y_true  = y_test_Incep.argmax(axis=1)\n",
        "y_test = y_test_Incep.argmax(axis=1)\n",
        "\n",
        "class_names = le_Incep.classes_\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.OrRd):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0lzS1r7UjHdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 16 sig fine bi adam\n"
      ],
      "metadata": {
        "id": "fsMp7t6KjQLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16\n",
        "filepath = \"model16_sig_fine_bi_adam\"                  ##\n",
        "filename = f\" {filepath}.h5 \"\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=2)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                          \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "acb4e593-91fd-41c4-caea-7fe6c4fce437",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDqdrrjjjQLB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:03<00:00, 95.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train_Incep, x_test_Incep, y_train_Incep, y_test_Incep ) = train_test_split(data_Incep, labels_Incep,\n",
        "\t                                                                                                test_size=0.25, random_state=40)"
      ],
      "metadata": {
        "id": "7xiXDxlkjQLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=2, activation=\"sigmoid\")(average_pooling_layer)   # unit 2\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "                                                ###\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "\n",
        "print(classification_report(y_test_Incep.argmax(axis=1),   pred_Incep.argmax(axis=1), target_names=le_Incep.classes_))\n",
        "\n",
        "\n",
        "#download ไฟล์ลงเครื่อง\n",
        "from google.colab import files\n",
        "files.download(filepath)     "
      ],
      "metadata": {
        "id": "ZR_mjoy_jQLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly import __version__\n",
        "%matplotlib inline\n",
        "\n",
        "import plotly.offline as pyo\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import iplot\n",
        "\n",
        "import cufflinks as cf\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
        "\n",
        "\n",
        "cf.go_offline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "404c1287-2b0e-4ff9-f82f-25f04d90eedd",
        "id": "pBnIOoZgjQLD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "H_Dense = H_Incep                            ##\n",
        "pred_Dense = pred_Incep                 ##\n",
        "\n",
        "accuracy = H_Dense.history['accuracy']\n",
        "val_accuracy  = H_Dense.history['val_accuracy']\n",
        "\n",
        "loss = H_Dense.history['loss']\n",
        "val_loss = H_Dense.history['val_loss']\n",
        "plt.figure(figsize=(20,15))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(accuracy, label = \"Training accuracy\")\n",
        "plt.plot(val_accuracy, label=\"Validation accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation accuracy\")\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(loss, label = \"Training loss\")\n",
        "plt.plot(val_loss, label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation loss\")\n",
        "\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_HFVBkwXjQLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_Incep.argmax(axis=1)            ##\n",
        "y_true  = y_test_Incep.argmax(axis=1)\n",
        "y_test = y_test_Incep.argmax(axis=1)\n",
        "\n",
        "class_names = le_Incep.classes_\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.OrRd):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mYt_S2KJjQLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "D8oy0TtDjQLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(filepath)"
      ],
      "metadata": {
        "id": "-p8vrVI8jQLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_model = model.predict(x_test_Incep)\n",
        "\n",
        "print(classification_report(y_test_Incep.argmax(axis=1),   pred_model.argmax(axis=1), target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "lZjXgo1WjQLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_model.argmax(axis=1)            ##\n",
        "y_true  = y_test_Incep.argmax(axis=1)\n",
        "y_test = y_test_Incep.argmax(axis=1)\n",
        "\n",
        "class_names = le_Incep.classes_\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.OrRd):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5OyAe7cNjQLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 16 sig fine bi sgd\n"
      ],
      "metadata": {
        "id": "-fEDyVnijSUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16\n",
        "filepath = \"model16_sig_fine_bi_sgd\"                  ##\n",
        "filename = f\" {filepath}.h5 \"\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=2)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                          \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "acb4e593-91fd-41c4-caea-7fe6c4fce437",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTZ7r9xhjSUJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:03<00:00, 95.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train_Incep, x_test_Incep, y_train_Incep, y_test_Incep ) = train_test_split(data_Incep, labels_Incep,\n",
        "\t                                                                                                test_size=0.25, random_state=40)"
      ],
      "metadata": {
        "id": "ZzOTt76jjSUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=2, activation=\"sigmoid\")(average_pooling_layer)   # unit 2\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "                                                ###\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "\n",
        "print(classification_report(y_test_Incep.argmax(axis=1),   pred_Incep.argmax(axis=1), target_names=le_Incep.classes_))\n",
        "\n",
        "\n",
        "#download ไฟล์ลงเครื่อง\n",
        "from google.colab import files\n",
        "files.download(filepath)     "
      ],
      "metadata": {
        "id": "6WwUPEyKjSUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly import __version__\n",
        "%matplotlib inline\n",
        "\n",
        "import plotly.offline as pyo\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import iplot\n",
        "\n",
        "import cufflinks as cf\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
        "\n",
        "\n",
        "cf.go_offline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "404c1287-2b0e-4ff9-f82f-25f04d90eedd",
        "id": "KNYp03aejSUK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "H_Dense = H_Incep                            ##\n",
        "pred_Dense = pred_Incep                 ##\n",
        "\n",
        "accuracy = H_Dense.history['accuracy']\n",
        "val_accuracy  = H_Dense.history['val_accuracy']\n",
        "\n",
        "loss = H_Dense.history['loss']\n",
        "val_loss = H_Dense.history['val_loss']\n",
        "plt.figure(figsize=(20,15))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(accuracy, label = \"Training accuracy\")\n",
        "plt.plot(val_accuracy, label=\"Validation accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation accuracy\")\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(loss, label = \"Training loss\")\n",
        "plt.plot(val_loss, label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation loss\")\n",
        "\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "edGfGv4JjSUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_Incep.argmax(axis=1)            ##\n",
        "y_true  = y_test_Incep.argmax(axis=1)\n",
        "y_test = y_test_Incep.argmax(axis=1)\n",
        "\n",
        "class_names = le_Incep.classes_\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.OrRd):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "42TDGKpQjSUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zEvhkxmPjSUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(filepath)"
      ],
      "metadata": {
        "id": "KQGDV0XKjSUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_model = model.predict(x_test_Incep)\n",
        "\n",
        "print(classification_report(y_test_Incep.argmax(axis=1),   pred_model.argmax(axis=1), target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "QEittf64jSUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_model.argmax(axis=1)            ##\n",
        "y_true  = y_test_Incep.argmax(axis=1)\n",
        "y_test = y_test_Incep.argmax(axis=1)\n",
        "\n",
        "class_names = le_Incep.classes_\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.OrRd):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wA5l6mvXjSUU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}